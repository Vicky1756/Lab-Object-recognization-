{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition\n",
    "\n",
    "The objective of this lab is very simple, to recognize objects in images. You will be working with a well-known dataset called CIFAR-10.\n",
    "\n",
    "You can learn more about this dataset and download it here:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "In the webpage above, they also included a few publications based on CIFAR-10 data, which showed some amazing accuracies. The worst network on the page (a shallow convolutional neural network) can classify images with rouhgly 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a function to load data\n",
    "\n",
    "The dataset webpage in the previous section also provide a simple way to load data from your harddrive using pickle. You may use their function for this exercise.\n",
    "\n",
    "Construct two numpy arrays for train images and train labels from data_batch_1 to data_batch_5. Then, construct two numpy arrays for test images, and test labels from test batch file. The original image size is 32 x 32 x 3. You may flatten the arrays so the final arrays are of size 1 x 3072."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(50000, 3072)\n",
    "y_train = y_train.reshape(-1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = X_test.reshape(10000, 3072)\n",
    "y_test = y_test.reshape(-1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify Dogs v.s. Cats\n",
    "\n",
    "Letâ€™s start simple by creating logistic regression model to classify images. We will select only two classes of images for this exercise.\n",
    "\n",
    "1. From 50,000 train images and 10,000 test images, we want to reduce the data size. Write code to filter only dog images (label = 3) and cat images (label = 5).\n",
    "2. Create a logistic regression model to classify cats and dogs. Report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "dog_images_train = []\n",
    "for i in range (0, 50000):\n",
    "    if labels[y_train[i]] == 'dog':\n",
    "        dog_images_train.append(X_train[i])\n",
    "print(len(dog_images_train))\n",
    "\n",
    "dog_images_test = []\n",
    "for i in range (0, 10000):\n",
    "    if labels[y_test[i]] == 'dog':\n",
    "        dog_images_test.append(X_test[i])\n",
    "print(len(dog_images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_labels_train = [3] * 5000\n",
    "dog_labels_test = [3] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "cat_images_train = []\n",
    "for i in range (0, 50000):\n",
    "    if labels[y_train[i]] == 'cat':\n",
    "        cat_images_train.append(X_train[i])\n",
    "print(len(dog_images_train))\n",
    "\n",
    "cat_images_test = []\n",
    "for i in range (0, 10000):\n",
    "    if labels[y_test[i]] == 'cat':\n",
    "        cat_images_test.append(X_test[i])\n",
    "print(len(dog_images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_labels_train = [5] * 5000\n",
    "cat_labels_test = [5] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_cat_images_train = np.array(dog_images_train + cat_images_train)\n",
    "dog_cat_labels_train = np.array(dog_labels_train + cat_labels_train)\n",
    "\n",
    "dog_cat_images_test = np.array(dog_images_test + cat_images_test)\n",
    "dog_cat_labels_test = np.array(dog_labels_test + cat_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=0)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(random_state = 0, max_iter = 2000)\n",
    "LR.fit(dog_cat_images_train, dog_cat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(dog_cat_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5805"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(dog_cat_labels_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Real Challenge\n",
    "\n",
    "The majority of your score for this lab will come from this real challenge. You are going to construct a neural network model to classify 10 classes of images from CIFAR-10 dataset. You will get half the credits for this one if you complete the assignment, and will get another half if you can exceed the target accuracy of 75%. (You may use any combination of sklearn, opencv, or tensorflow to do this exercise).\n",
    "\n",
    "Design at least 3 variants of neural network models. Each model should have different architectures. (Do not vary just a few parameters, the architecture of the network must change in each model). In your notebook, explain your experiments in details and display the accuracy score for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first experiment using CNN \n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils \n",
    "from keras import backend \n",
    "import keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the inputs from 0-255 to 0-1 ,as pixels have value in the range 0-255 hence we need to normalize the value \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train = X_train / 255.0 \n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs for better prediction \n",
    "y_train = np_utils.to_categorical(y_train) \n",
    "y_test = np_utils.to_categorical(y_test) \n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using sequentia as it allows to create the model layer-by-layer\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the required layers for CNN\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='relu', padding='same')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3))) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3))) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,915,114\n",
      "Trainable params: 2,915,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1563/1563 [==============================] - 187s 119ms/step - loss: 1.0539 - accuracy: 0.6259 - val_loss: 0.8521 - val_accuracy: 0.7001\n",
      "Epoch 2/40\n",
      "1563/1563 [==============================] - 186s 119ms/step - loss: 0.8366 - accuracy: 0.7040 - val_loss: 0.7826 - val_accuracy: 0.7251\n",
      "Epoch 3/40\n",
      "1563/1563 [==============================] - 185s 119ms/step - loss: 0.7328 - accuracy: 0.7402 - val_loss: 0.7422 - val_accuracy: 0.7425\n",
      "Epoch 4/40\n",
      "1563/1563 [==============================] - 188s 120ms/step - loss: 0.6653 - accuracy: 0.7650 - val_loss: 0.7143 - val_accuracy: 0.7479\n",
      "Epoch 5/40\n",
      "1563/1563 [==============================] - 173s 111ms/step - loss: 0.6202 - accuracy: 0.7821 - val_loss: 0.6826 - val_accuracy: 0.7609\n",
      "Epoch 6/40\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.5874 - accuracy: 0.7915 - val_loss: 0.6741 - val_accuracy: 0.7663\n",
      "Epoch 7/40\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 0.5517 - accuracy: 0.8048 - val_loss: 0.6595 - val_accuracy: 0.7697\n",
      "Epoch 8/40\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.5302 - accuracy: 0.8113 - val_loss: 0.6349 - val_accuracy: 0.7783\n",
      "Epoch 9/40\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.5119 - accuracy: 0.8180 - val_loss: 0.6386 - val_accuracy: 0.7788\n",
      "Epoch 10/40\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.4906 - accuracy: 0.8268 - val_loss: 0.6436 - val_accuracy: 0.7785\n",
      "Epoch 11/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4748 - accuracy: 0.8319 - val_loss: 0.6266 - val_accuracy: 0.7816\n",
      "Epoch 12/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4626 - accuracy: 0.8366 - val_loss: 0.6305 - val_accuracy: 0.7826\n",
      "Epoch 13/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4441 - accuracy: 0.8418 - val_loss: 0.6197 - val_accuracy: 0.7851\n",
      "Epoch 14/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4351 - accuracy: 0.8453 - val_loss: 0.6349 - val_accuracy: 0.7832\n",
      "Epoch 15/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4246 - accuracy: 0.8484 - val_loss: 0.6157 - val_accuracy: 0.7856\n",
      "Epoch 16/40\n",
      "1563/1563 [==============================] - 148s 95ms/step - loss: 0.4178 - accuracy: 0.8507 - val_loss: 0.6166 - val_accuracy: 0.7884\n",
      "Epoch 17/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4058 - accuracy: 0.8549 - val_loss: 0.6200 - val_accuracy: 0.7905\n",
      "Epoch 18/40\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.3986 - accuracy: 0.8568 - val_loss: 0.6126 - val_accuracy: 0.7909\n",
      "Epoch 19/40\n",
      "1563/1563 [==============================] - 149s 96ms/step - loss: 0.3933 - accuracy: 0.8599 - val_loss: 0.6127 - val_accuracy: 0.7934\n",
      "Epoch 20/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3807 - accuracy: 0.8641 - val_loss: 0.6279 - val_accuracy: 0.7897\n",
      "Epoch 21/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3745 - accuracy: 0.8650 - val_loss: 0.6120 - val_accuracy: 0.7938\n",
      "Epoch 22/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3679 - accuracy: 0.8684 - val_loss: 0.6190 - val_accuracy: 0.7927\n",
      "Epoch 23/40\n",
      "1563/1563 [==============================] - 151s 96ms/step - loss: 0.3657 - accuracy: 0.8681 - val_loss: 0.6092 - val_accuracy: 0.7959\n",
      "Epoch 24/40\n",
      "1563/1563 [==============================] - 151s 96ms/step - loss: 0.3570 - accuracy: 0.8710 - val_loss: 0.6148 - val_accuracy: 0.7953\n",
      "Epoch 25/40\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.3487 - accuracy: 0.8763 - val_loss: 0.6233 - val_accuracy: 0.7918\n",
      "Epoch 26/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3385 - accuracy: 0.8792 - val_loss: 0.6207 - val_accuracy: 0.7947\n",
      "Epoch 27/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3388 - accuracy: 0.8795 - val_loss: 0.6176 - val_accuracy: 0.7962\n",
      "Epoch 28/40\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.3369 - accuracy: 0.8795 - val_loss: 0.6216 - val_accuracy: 0.7952\n",
      "Epoch 29/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3265 - accuracy: 0.8841 - val_loss: 0.6167 - val_accuracy: 0.7971\n",
      "Epoch 30/40\n",
      "1563/1563 [==============================] - 149s 96ms/step - loss: 0.3309 - accuracy: 0.8823 - val_loss: 0.6147 - val_accuracy: 0.7980\n",
      "Epoch 31/40\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3216 - accuracy: 0.8824 - val_loss: 0.6175 - val_accuracy: 0.7979\n",
      "Epoch 32/40\n",
      "1563/1563 [==============================] - 151s 96ms/step - loss: 0.3201 - accuracy: 0.8859 - val_loss: 0.6180 - val_accuracy: 0.7959\n",
      "Epoch 33/40\n",
      "1563/1563 [==============================] - 151s 96ms/step - loss: 0.3113 - accuracy: 0.8897 - val_loss: 0.6218 - val_accuracy: 0.7985\n",
      "Epoch 34/40\n",
      "1563/1563 [==============================] - 151s 96ms/step - loss: 0.3143 - accuracy: 0.8870 - val_loss: 0.6199 - val_accuracy: 0.7966\n",
      "Epoch 35/40\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.3064 - accuracy: 0.8895 - val_loss: 0.6119 - val_accuracy: 0.7991\n",
      "Epoch 36/40\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.3012 - accuracy: 0.8926 - val_loss: 0.6171 - val_accuracy: 0.7999\n",
      "Epoch 37/40\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.2975 - accuracy: 0.8936 - val_loss: 0.6186 - val_accuracy: 0.7984\n",
      "Epoch 38/40\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.2979 - accuracy: 0.8916 - val_loss: 0.6181 - val_accuracy: 0.8000\n",
      "Epoch 39/40\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.2918 - accuracy: 0.8958 - val_loss: 0.6257 - val_accuracy: 0.7977\n",
      "Epoch 40/40\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.2887 - accuracy: 0.8967 - val_loss: 0.6200 - val_accuracy: 0.7997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15eb5196490>"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model \n",
    "epochs = 10\n",
    "Irate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr = Irate, momentum=0.9, decay=lrate/epochs, nesterov=False,) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=32) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 154s 99ms/step - loss: 0.2813 - accuracy: 0.8991 - val_loss: 0.6202 - val_accuracy: 0.8006\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.2760 - accuracy: 0.9001 - val_loss: 0.6246 - val_accuracy: 0.8013\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 151s 97ms/step - loss: 0.2733 - accuracy: 0.9017 - val_loss: 0.6243 - val_accuracy: 0.8025\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.2727 - accuracy: 0.9031 - val_loss: 0.6287 - val_accuracy: 0.8007\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 149s 95ms/step - loss: 0.2675 - accuracy: 0.9034 - val_loss: 0.6294 - val_accuracy: 0.7993\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.2631 - accuracy: 0.9055 - val_loss: 0.6294 - val_accuracy: 0.7990\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 154s 98ms/step - loss: 0.2630 - accuracy: 0.9050 - val_loss: 0.6224 - val_accuracy: 0.8017\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.2630 - accuracy: 0.9058 - val_loss: 0.6331 - val_accuracy: 0.8011\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.2595 - accuracy: 0.9068 - val_loss: 0.6266 - val_accuracy: 0.8006\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.2571 - accuracy: 0.9069 - val_loss: 0.6311 - val_accuracy: 0.8014\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32) \n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test, y_test, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second experiment \n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=(32,32,3)))\n",
    "model_2.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "model_2.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "model_2.add(MaxPooling2D((2, 2)))\n",
    "model_2.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "model_2.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1),  padding='same'))\n",
    "model_2.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1),  padding='same'))\n",
    "model_2.add(MaxPooling2D((2, 2)))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(256, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(128, activation='relu'))\n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "model_2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 16, 16, 16)        9232      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,150,746\n",
      "Trainable params: 1,150,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 106s 68ms/step - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15edcf164c0>"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model \n",
    "epochs = 12\n",
    "Irate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr = Irate, momentum= 1, decay=lrate/epochs, nesterov=False,) \n",
    "model_2.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 119s 76ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32) \n",
    "# Final evaluation of the model \n",
    "scores = model_2.evaluate(X_test, y_test, verbose=0) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
